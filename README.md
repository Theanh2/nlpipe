PROGRAMMING A PIPELINE FOR NATURAL LANGUAGE PROCESSING
> I program multiple Pipelines for the use in natural language processing.
> The main focus is user friendly code that can be run without deep knowledge about language processing, while maintaining the modularity to change hyper/parameter and techniques as you like.

## Table of Contents
* [General Info](#general-information)
* [Main libraries](#Main-libraries)
* [Usage](#usage)
* [Room for Improvement](#room-for-improvement)
* [Contact](#contact)

## General Information
These Pipelines are written as part of my bachelor's thesis and supervised by Prof. Dr. Christian Heumann and Dr. Matthias Aßenmacher
The goal of the pipelines is to simplify the use of natural language processing techniques. There exist a wide array of good packages but there is not a unified API for all of them.
These Pipelines wrap a lot of them together, so that it is more manageable and add a few more functionalities and quality of life features to the wrapped functions.
Especially for beginners it can be easier to set up the virtual environment with a requirement file and a flowchart-like workflow.

## Main libraries
- Transformer
- Scikit-learn
- datasets
- tokenizers
- nltk

## Usage
For more information about the Pipelines you can read my bachelor's thesis.
Code examples and documentation for each function is provided in the appendix.

## Room for Improvement
- databank of raw text for tokenization training
- More supported models for nlpipe
- Visualizations of tuning

## Contact
Many thanks to my supervisors: Prof. Dr. Christian Heumann, Dr. Matthias Aßenmacher

Created by The Anh Vu, feel free to give me any tips for improvement!
Theanh_v99@yahoo.de

